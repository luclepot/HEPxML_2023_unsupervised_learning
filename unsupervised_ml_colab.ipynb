{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ZCkGvRShbn3",
   "metadata": {
    "id": "3ZCkGvRShbn3"
   },
   "source": [
    "## pre-introduction and github download:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exQfc_wdhieo",
   "metadata": {
    "id": "exQfc_wdhieo"
   },
   "outputs": [],
   "source": [
    "! wget https://github.com/luclepot/HEPxML_2023_unsupervised_learning/raw/main/data/events_anomalydetection_DelphesHerwig_qcd_features.h5\n",
    "! wget https://github.com/luclepot/HEPxML_2023_unsupervised_learning/raw/main/data/events_anomalydetection_DelphesPythia8_v2_Wprime_features.h5\n",
    "! wget https://github.com/luclepot/HEPxML_2023_unsupervised_learning/raw/main/data/events_anomalydetection_DelphesPythia8_v2_qcd_features.h5\n",
    "! mkdir data/\n",
    "! mv *.h5 data/\n",
    "! wget https://github.com/luclepot/HEPxML_2023_unsupervised_learning/raw/main/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de1d1f2",
   "metadata": {
    "id": "5de1d1f2"
   },
   "source": [
    "# Introduction to unsupervised machine learning\n",
    "\n",
    "This notebook will aim to provide a few examples of unsupervised machine learning as applied to particle physics datasets.\n",
    "\n",
    "we're using the [LHCOlympics dataset from 2020](https://www.google.com/search?q=lhcolypmics+2020&oq=lhcolypmics+2020&aqs=chrome..69i57j0i546l3.4495j0j7&sourceid=chrome&ie=UTF-8), with some post-processing. This dataset features dijet events from three distributions:\n",
    "\n",
    "- `herwig` generated QCD\n",
    "- `pythia` generated QCD (different simulator)\n",
    "- `pythia` generated $W^\\prime$ boson (resonant in invariant mass)\n",
    "\n",
    "While we have the truth labels for our dataset, the goal of this notebook will be to show how we can find this signal in our data without using the direct truth labels. As discussed in the notes, generic searches for new physics are more important now than ever, with the lack of success of traditional new physics searches up to this point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32862ce6",
   "metadata": {
    "id": "32862ce6"
   },
   "source": [
    "### Pre-ML unsupervised searches\n",
    "\n",
    "A good overview (and the last of such searches on ATLAS) is provided by [https://arxiv.org/abs/1807.07447](this ATLAS search). In general the searches focused on calculating deviations from expected densities in a variety of signal search regions. \n",
    "\n",
    "The paper found no significant p-value deviations in $10^5$ regions, but covered quite a bit of search space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da74763e",
   "metadata": {
    "id": "da74763e"
   },
   "source": [
    "### Dataset creation\n",
    "\n",
    "For this study, we'll use a single test dataset, where the significance of the signal in the dataset is 2$\\sigma$. \n",
    "\n",
    "Signal significance depends on the dataset size, and is expected for a dataset with a number of signal events $s$ and a number of background events $b$ as\n",
    "\n",
    "$$\n",
    "\\text{median}[Z_0 | s + b] = \\frac{s}{\\sqrt{b}}\n",
    "$$\n",
    "\n",
    "This is the median expected significance for signal and background. Generally, we measure the quality of our models by determining their ability to amplify this signal.\n",
    "\n",
    "Throughout this notebook, we will be taking `pythia` generated data to be \"real data,\" and `herwig` generated data to be \"simulated data.\" This allows us to see our effects of simulation help on finding new signals.\n",
    "\n",
    "First, we will set the signal/sideband regions for this setting. this is used to constrain the data a bit, to be within a specific $m_{jj}$ region. We can choose the areas where the background qcd is flatly decreasing, i.e. 2700 to 6000. This makes it easier for the models to find the signal, which is definitely cheating - but, normally we would scan across the $m_{jj}$ spectrum and achieve approximately the same effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfcbbbe",
   "metadata": {
    "id": "adfcbbbe"
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# set signal region for this signal (only used for later)\n",
    "# set total region for this signal (want to constrain it a bit!)\n",
    "sr = 3200, 3800\n",
    "sb = 2500, 4500\n",
    "\n",
    "ROCS = {}\n",
    "\n",
    "# use our utility function to import the data alltogether\n",
    "all_data = utils.load_LHCO()\n",
    "all_data = all_data[all_data.mjj.between(*sb)]\n",
    "\n",
    "# select \"data\", \"simulation\", and \"signal\"\n",
    "data = all_data[(all_data.herwig == 0) & (all_data.signal == 0)]\n",
    "sim = all_data[(all_data.herwig == 1) & (all_data.signal == 0)]\n",
    "signal = all_data[(all_data.herwig == 0) & (all_data.signal == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7737e58f",
   "metadata": {
    "id": "7737e58f"
   },
   "source": [
    "Next, we plot the dataset and our selected signal regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8330b65",
   "metadata": {
    "id": "f8330b65"
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(all_data.mjj.min(), all_data.mjj.max(), 100)\n",
    "plt.hist(data.mjj, bins=bins, label='Data', histtype='step', density=1)\n",
    "plt.hist(sim.mjj, bins=bins, label='Simulation', histtype='step', density=1)\n",
    "plt.hist(signal.mjj, bins=bins, label='Signal', alpha=0.5, density=1)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Invariant Dijet Mass $m_{jj}$ (GeV/c$^2$)', fontsize=20)\n",
    "plt.ylabel('Density', fontsize=20)\n",
    "\n",
    "plt.axvline(sr[0], color='tab:grey', ls=':')\n",
    "plt.axvline(sr[1], color='tab:grey', ls=':', label='SR (for SALAD/CWoLa)')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7ffa14",
   "metadata": {
    "id": "fb7ffa14"
   },
   "source": [
    "First, we'll fix our signal significance (in the signal region training dataset) at 2$\\sigma$. We can pick a test fraction of 0.5, and a training fraction of 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f46ff1d",
   "metadata": {
    "id": "9f46ff1d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "test_frac = 0.5\n",
    "train_frac = 0.8\n",
    "\n",
    "\n",
    "data_train, data_test = train_test_split(data, test_size=test_frac)\n",
    "sim_train, sim_test = train_test_split(sim, test_size=test_frac)\n",
    "\n",
    "sig = 2.0 # sigma\n",
    "n_sig = int(np.round(sig*np.sqrt(len(data_train)),0))\n",
    "signal_test, signal_train = train_test_split(signal, test_size=n_sig/len(signal))\n",
    "\n",
    "# add data to signal to make \"data\"\n",
    "data_train, data_test = pd.concat([data_train, signal_train]), pd.concat([data_test, signal_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4c17c3",
   "metadata": {
    "id": "0c4c17c3"
   },
   "source": [
    "Now we can plot this, and see exactly what is in our training dataset. The test set should look approximately the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3bd23c",
   "metadata": {
    "id": "af3bd23c"
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(all_data.mjj.min(), all_data.mjj.max(), 100)\n",
    "plt.hist(data_train[~data_train.signal.astype(bool)].mjj, bins=bins, label='Training Data', histtype='step', density=0)\n",
    "plt.hist(sim_train.mjj, bins=bins, label='Training Simulation', histtype='step', density=0)\n",
    "plt.hist(data_train[data_train.signal.astype(bool)].mjj, bins=bins, label='Training Signal', alpha=0.5, density=0)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Invariant Dijet Mass $m_{jj}$ (GeV/c$^2$)', fontsize=20)\n",
    "plt.ylabel('Count', fontsize=20)\n",
    "\n",
    "plt.axvline(sr[0], color='tab:grey', ls=':')\n",
    "plt.axvline(sr[1], color='tab:grey', ls=':', label='SR (for SALAD/CWoLa)')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim(plt.ylim()[0], 2e5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f2d6e",
   "metadata": {
    "id": "407f2d6e"
   },
   "source": [
    "Great! Now we can move to start training various models and evaluating their performances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed66a091",
   "metadata": {
    "id": "ed66a091"
   },
   "source": [
    "### t-SNE\n",
    "\n",
    "This is the easiest model to run, though the operating mechanics are confusing to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b84ec",
   "metadata": {
    "id": "243b84ec"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "n_fit = 5000\n",
    "n_components = 2\n",
    "n_iter = 250\n",
    "\n",
    "features = [\n",
    "#     'pxj1', 'pyj1', 'pzj1', 'mj1', 'tau1j1', 'tau2j1', 'tau3j1', 'pxj2',\n",
    "#     'pyj2', 'pzj2', 'mj2', 'tau1j2', 'tau2j2', 'tau3j2', \n",
    "    'mjj', 'pTj1', 'pTj2', 'maxmass', 'minmass', 'tau21a', 'tau21b'\n",
    "]\n",
    "\n",
    "tsne_train = data_train.sample(n_fit)\n",
    "norm_factors = data_train[features].max(axis=0).values\n",
    "\n",
    "tsne = TSNE(n_components=n_components, n_iter=n_iter, verbose=2)\n",
    "tsne_xhat = tsne.fit_transform((tsne_train[features]/norm_factors))\n",
    "\n",
    "plt.scatter(*tsne_xhat[tsne_train.signal==0].T, s=0.5, label='data')\n",
    "plt.scatter(*tsne_xhat[tsne_train.signal==1].T, s=10, label='signal')\n",
    "plt.xlabel('$z_0$', fontsize=18)\n",
    "plt.ylabel('$z_1$', fontsize=18)\n",
    "plt.title('TSNE, S/B = {:.4f}, $\\sigma$ = {:.1f}'.format(\n",
    "    np.divide(*tsne_train.signal.value_counts().values[::-1]),\n",
    "    tsne_train.signal.sum()/np.sqrt((tsne_train.signal==0).sum())\n",
    "), fontsize=22)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634592b0",
   "metadata": {
    "id": "634592b0"
   },
   "source": [
    "As you will likely see, the separation doesn't work very well. This is because there simply is not enough signal events (or they are not different enough from the qcd events) for them to show up distinctly in the scatter plot made by TSNE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5658237e",
   "metadata": {
    "id": "5658237e"
   },
   "source": [
    "However, if we train on a much higher signal density, it will recognize (the test dataset has high signal density, something like 1:1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f63e3b",
   "metadata": {
    "id": "f1f63e3b"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "n_fit = 5000\n",
    "n_components = 2\n",
    "n_iter = 250\n",
    "\n",
    "features = [\n",
    "#     'pxj1', 'pyj1', 'pzj1', 'mj1', 'tau1j1', 'tau2j1', 'tau3j1', 'pxj2',\n",
    "#     'pyj2', 'pzj2', 'mj2', 'tau1j2', 'tau2j2', 'tau3j2', \n",
    "    'mjj', 'pTj1', 'pTj2', 'maxmass', 'minmass', 'tau21a', 'tau21b'\n",
    "]\n",
    "\n",
    "tsne_train = pd.concat([data_test, sim_test]).sample(n_fit)\n",
    "norm_factors = data_test[features].max(axis=0).values\n",
    "\n",
    "tsne = TSNE(n_components=n_components, n_iter=n_iter, verbose=2)\n",
    "tsne_xhat = tsne.fit_transform((tsne_train[features]/norm_factors))\n",
    "\n",
    "plt.scatter(*tsne_xhat[(tsne_train.signal==0) & (tsne_train.herwig == 0)].T, s=0.5, label='data')\n",
    "plt.scatter(*tsne_xhat[(tsne_train.signal==0) & (tsne_train.herwig == 1)].T, s=0.5, label='sim')\n",
    "plt.scatter(*tsne_xhat[(tsne_train.signal==1) & (tsne_train.herwig == 0)].T, s=0.5, label='signal')\n",
    "plt.legend()\n",
    "plt.xlabel('$z_0$', fontsize=18)\n",
    "plt.ylabel('$z_1$', fontsize=18)\n",
    "plt.title('TSNE, S/B = {:.4f}, $\\sigma$ = {:.1f}'.format(\n",
    "    np.divide(*tsne_train.signal.value_counts().values[::-1]),\n",
    "    tsne_train.signal.sum()/np.sqrt((tsne_train.signal==0).sum())\n",
    "), fontsize=22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b9a13c",
   "metadata": {
    "id": "d7b9a13c"
   },
   "source": [
    "If we thought this representation was particularly good, we could train a neural network to discriminate between the two.\n",
    "\n",
    "#### Challenge:\n",
    "\n",
    "Train a neural network to learn the mapping from input dataset to TSNE output, so that it can be applied to arbitrary data (TSNE is a transform and cannot be applied to any dataset, it must also learn from it)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d08641f",
   "metadata": {
    "id": "1d08641f"
   },
   "source": [
    "# Autoencoder\n",
    "\n",
    "Autoencoders were one of the first applications of ML to physics anomaly detection. \n",
    "[This paper](https://arxiv.org/abs/1811.10276) from 2018 is an implementation of variational autoencoders (we will build up to this principle).\n",
    "\n",
    "The basic principle of an autoencoder is to learn a latent representation of a dataset, and then identifying outliers in this dataset as \"signal.\" This is done by training a network to reproduce the input data exactly, under some constraint. \n",
    "\n",
    "This constraint comes in various formats, but for a neural autoencoder (which we are starting with) it is done simply by creating a bottleneck of nodes in the architecture, as shown here: \n",
    "\n",
    "We continue our code by doing this here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7b35b7",
   "metadata": {
    "id": "9f7b35b7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dims, middle, input_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, middle)\n",
    "        self.linear2 = nn.Linear(middle, middle)\n",
    "        self.linear3 = nn.Linear(middle, latent_dims)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        z = self.linear3(x)\n",
    "        return z\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dims, middle, input_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(latent_dims, middle)\n",
    "        self.linear2 = nn.Linear(middle, middle)\n",
    "        self.linear3 = nn.Linear(middle, input_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = F.relu(self.linear1(z))\n",
    "        z = F.relu(self.linear2(z))\n",
    "        z = F.tanh(self.linear3(z))\n",
    "        return z\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, n_features, neck, middle):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(neck, middle, n_features)\n",
    "        self.decoder = Decoder(neck, middle, n_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        x = self.decoder(latent)\n",
    "        return x,latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a64a8",
   "metadata": {
    "id": "445a64a8"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "features = [\n",
    "#     'pxj1', 'pyj1', 'pzj1', 'mj1', 'tau1j1', 'tau2j1', 'tau3j1', 'pxj2',\n",
    "#     'pyj2', 'pzj2', 'mj2', 'tau1j2', 'tau2j2', 'tau3j2', \n",
    "    'mjj', 'pTj1', 'pTj2', 'maxmass', 'minmass', 'tau21a', 'tau21b'\n",
    "]\n",
    "neck = 2\n",
    "middle = 4\n",
    "\n",
    "batch_size=500\n",
    "learning_rate = 1e-3\n",
    "epochs = 10\n",
    "\n",
    "ae = Autoencoder(len(features), neck, middle)\n",
    "crit = nn.MSELoss()\n",
    "opt = torch.optim.AdamW(ae.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69fb480",
   "metadata": {
    "id": "f69fb480"
   },
   "outputs": [],
   "source": [
    "norm_factors = data_train[features].max(axis=0)\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    torch.Tensor((data_train[features]/norm_factors).values),\n",
    "    [train_frac, 1-train_frac]\n",
    ")\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "for epoch in range(epochs):\n",
    "    iterator = tqdm.tqdm(train_dl, total=len(train_dl), desc='Epoch {:>3}, last loss {:>7.3f}'.format(epoch, -1 if epoch == 0 else losses[epoch-1]))\n",
    "    for x in iterator:\n",
    "        xhat, z = ae(x)\n",
    "        loss = crit(xhat, x)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    ae.eval()\n",
    "    xhattest,_ = ae(val_dataset.dataset)\n",
    "    val_loss = crit(xhattest, val_dataset.dataset)\n",
    "    \n",
    "    val_losses.append(val_loss.data.item())\n",
    "    losses.append(loss.data.item())\n",
    "    \n",
    "plt.plot(losses, label='Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch', fontsize=20)\n",
    "plt.ylabel('MSE Loss', fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebf3e9d",
   "metadata": {
    "id": "0ebf3e9d"
   },
   "source": [
    "It is interesting to get the MSE, and then to plot both that and the latent space. This gives some intuition as to what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740aa0f8",
   "metadata": {
    "id": "740aa0f8"
   },
   "outputs": [],
   "source": [
    "xhat, z = ae(torch.Tensor((data_test[features]/norm_factors).values))\n",
    "_, ztrain = ae(torch.Tensor((data_train[features]/norm_factors).values))\n",
    "\n",
    "mse = (data_test[features]/norm_factors - xhat.detach().numpy())**2.\n",
    "z = z.detach().numpy()\n",
    "ztrain = ztrain.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebceaee",
   "metadata": {
    "id": "bebceaee"
   },
   "source": [
    "MSE plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53598c1f",
   "metadata": {
    "id": "53598c1f"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 4))\n",
    "bins = np.logspace(np.log10(mse.values.min()), np.log10(mse.values.max()), 100)\n",
    "\n",
    "for i,name in enumerate(['qcd', 'signal', 'combined']):\n",
    "    ax = axs[i]\n",
    "    if i == 2:\n",
    "        bins = np.logspace(np.log10(mse.mean(axis=1).values.min()), np.log10(mse.mean(axis=1).values.max()), 100)\n",
    "        ax.hist(mse[data_test.signal == 0].mean(axis=1), label='qcd', histtype='step', bins=bins, density=1)\n",
    "        ax.hist(mse[data_test.signal == 1].mean(axis=1), label='signal', histtype='step', bins=bins, density=1)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        bins = np.logspace(np.log10(mse.values.min()), np.log10(mse.values.max()), 100)\n",
    "        for c in mse:\n",
    "            ax.hist(\n",
    "                mse[data_test.signal == i][c], bins=bins, \n",
    "                label=c, histtype='step'\n",
    "            )\n",
    "    ax.legend()\n",
    "    ax.set_xscale('log')\n",
    "    if i == 2:\n",
    "        ax.set_ylabel('Density', fontsize=18)\n",
    "    else:\n",
    "        ax.set_ylabel('Count', fontsize=18)\n",
    "        ax.set_xlim(1e-9, 1e0)\n",
    "    ax.grid()\n",
    "    ax.set_xlabel('Autoencoder MSE', fontsize=18)\n",
    "    ax.set_title(name, fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc6e320",
   "metadata": {
    "id": "cdc6e320"
   },
   "source": [
    "Latent space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023293ee",
   "metadata": {
    "id": "023293ee"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axs = axs.flatten()\n",
    "bx, by = [np.linspace(*arg, 50) for arg in zip(z.min(axis=0), z.max(axis=0))]\n",
    "vals = []\n",
    "for i,name in enumerate(['qcd', 'signal']):\n",
    "    ax = axs[i]\n",
    "    h = ax.hist2d(z[data_test.signal == i,0], z[data_test.signal == i,1], bins=(bx, by), density=1)\n",
    "    vals.append(h[0])\n",
    "    fig.colorbar(h[3], ax=ax, label='Test Density')\n",
    "    ax.set_xlabel('$z_0$', fontsize=18)\n",
    "    ax.set_ylabel('$z_1$', fontsize=18)\n",
    "    ax.set_title(name, fontsize=20)\n",
    "ax = axs[2]\n",
    "h = ax.pcolor(np.nan_to_num(vals[1].T/vals[0].T, 1, posinf=1))\n",
    "fig.colorbar(h, ax=ax, label='Ratio of Signal/QCD Densities',)\n",
    "ax.set_xlabel('$z_0$', fontsize=18)\n",
    "ax.set_ylabel('$z_1$', fontsize=18)\n",
    "ax.set_title('signal/qcd', fontsize=20)\n",
    "\n",
    "ax = axs[3]\n",
    "h = ax.hist2d(*ztrain.T, bins=(bx, by), norm=mpl.colors.LogNorm())\n",
    "fig.colorbar(h[3], ax=ax, label='Log Density', )\n",
    "ax.set_xlabel('$z_0$', fontsize=18)\n",
    "ax.set_ylabel('$z_1$', fontsize=18)\n",
    "ax.set_title('training set combined density', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952dd006",
   "metadata": {
    "id": "952dd006"
   },
   "source": [
    "Lastly, we need to get the ROC/AUC scores and significance improvement. Sklearn can help us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce5b0a5",
   "metadata": {
    "id": "2ce5b0a5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc,roc_auc_score\n",
    "\n",
    "name = 'Neural Autoencoder'\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "# try with other yhats! z[:,0], np.mean(z, axis=1), etc. some might work better.\n",
    "yhat = mse.mean(axis=1)\n",
    "fpr, tpr, thresh = roc_curve(data_test.signal, yhat)\n",
    "this_auc = auc(fpr, tpr)\n",
    "ax = axs[0]\n",
    "ax.plot(fpr, tpr, label='{}, AUC={:.4f}'.format(name, this_auc))\n",
    "ax.plot(fpr, fpr, ls=':', color='tab:grey')\n",
    "ax.set_ylabel('True Positive Rate', fontsize=18)\n",
    "ax.set_xlabel('False Positive Rate', fontsize=18)\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax = axs[1]\n",
    "ax.plot(tpr, tpr/np.sqrt(fpr))\n",
    "ax.set_xlabel('True Positive Rate', fontsize=18)\n",
    "ax.set_ylabel('Significance Improvement $\\sigma$', fontsize=18)\n",
    "ax.axhline(1.0, ls=':', color='tab:grey')\n",
    "ax.grid()\n",
    "ROCS[name] = tpr, fpr, this_auc\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fbd75e",
   "metadata": {
    "id": "a9fbd75e"
   },
   "source": [
    "# Variational autoencoder\n",
    "\n",
    "\n",
    "This time we are doing basically the same thing as we did with the Autoencoder, but adding the variational bottleneck as described in lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd4db5d",
   "metadata": {
    "id": "bcd4db5d"
   },
   "outputs": [],
   "source": [
    "class VariationalEncoder(nn.Module):\n",
    "    def __init__(self, latent_dims, middle, input_dim):\n",
    "        super(VariationalEncoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, middle)\n",
    "        self.linear2 = nn.Linear(middle, middle)\n",
    "        self.linear3 = nn.Linear(middle, latent_dims)\n",
    "        self.linear4 = nn.Linear(middle, latent_dims)\n",
    "\n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "#         self.N.loc = self.N.loc.cuda() # hack to get sampling on the GPU\n",
    "#         self.N.scale = self.N.scale.cuda()\n",
    "        self.kl = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        mu =  self.linear3(x)\n",
    "        sigma = torch.exp(self.linear4(x))\n",
    "        z = mu + sigma*self.N.sample(mu.shape)\n",
    "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()\n",
    "        return z\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dims, middle, input_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = nn.Linear(latent_dims, middle)\n",
    "        self.linear2 = nn.Linear(middle, middle)\n",
    "        self.linear3 = nn.Linear(middle, input_dim)\n",
    "        \n",
    "\n",
    "    def forward(self, z):\n",
    "        z = F.relu(self.linear1(z))\n",
    "        z = F.relu(self.linear2(z))\n",
    "        z = F.sigmoid(self.linear3(z))\n",
    "        return z\n",
    "    \n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self,  n_features, neck, middle):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        self.encoder = VariationalEncoder(neck, middle, n_features)\n",
    "        self.decoder = Decoder(neck, middle, n_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x = self.decoder(z)\n",
    "        return x,z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33810c18",
   "metadata": {
    "id": "33810c18"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "features = [\n",
    "#     'pxj1', 'pyj1', 'pzj1', 'mj1', 'tau1j1', 'tau2j1', 'tau3j1', 'pxj2',\n",
    "#     'pyj2', 'pzj2', 'mj2', 'tau1j2', 'tau2j2', 'tau3j2', \n",
    "    'mjj', 'pTj1', 'pTj2', 'maxmass', 'minmass', 'tau21a', 'tau21b'\n",
    "]\n",
    "neck = 2\n",
    "middle = 4\n",
    "learning_rate = 5e-5\n",
    "epochs = 10\n",
    "\n",
    "vae = VariationalAutoencoder(len(features), neck, middle)\n",
    "opt = torch.optim.AdamW(vae.parameters(), lr=learning_rate)\n",
    "\n",
    "norm_factors = data_train[features].max(axis=0)\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    torch.Tensor((data_train[features]/norm_factors).values),\n",
    "    [train_frac, 1-train_frac]\n",
    ")\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    iterator = tqdm.tqdm(train_dl, total=len(train_dl), desc='Epoch {:>3}, last loss {:>7.3f}'.format(epoch, -1 if epoch == 0 else losses[epoch-1]))\n",
    "    for x in iterator:\n",
    "        xhat, z = vae(x)\n",
    "        loss = ((x - xhat)**2.).sum() + vae.encoder.kl\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    vae.eval()\n",
    "    xhattest,_ = vae(val_dataset.dataset)\n",
    "    val_loss = ((val_dataset.dataset - xhattest)**2.).sum()\n",
    "    \n",
    "    val_losses.append(val_loss.data.item())\n",
    "    losses.append(loss.data.item())\n",
    "\n",
    "ax = plt.gca()\n",
    "ax1 = ax.twinx()\n",
    "h1 = ax.plot(losses, label='Loss')\n",
    "h2 = ax1.plot(val_losses, label='Val Loss', color='tab:orange')\n",
    "ax.set_xlabel('Epoch', fontsize=20)\n",
    "ax.set_ylabel('Loss', fontsize=20)\n",
    "ax1.set_ylabel('Val Loss', fontsize=20, rotation=270, va='bottom')\n",
    "\n",
    "plt.legend(labels=['Loss', 'Val Loss'], handles = h1 +h2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50af4885",
   "metadata": {
    "id": "50af4885"
   },
   "outputs": [],
   "source": [
    "xhat, z = vae(torch.Tensor((data_test[features]/norm_factors).values))\n",
    "_, ztrain = vae(torch.Tensor((data_train[features]/norm_factors).values))\n",
    "\n",
    "mse = (data_test[features]/norm_factors - xhat.detach().numpy())**2.\n",
    "z = z.detach().numpy()\n",
    "ztrain = ztrain.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c405eeb9",
   "metadata": {
    "id": "c405eeb9"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 4))\n",
    "bins = np.logspace(np.log10(mse.values.min()), np.log10(mse.values.max()), 100)\n",
    "\n",
    "for i,name in enumerate(['qcd', 'signal', 'combined']):\n",
    "    ax = axs[i]\n",
    "    if i == 2:\n",
    "        bins = np.logspace(np.log10(mse.mean(axis=1).values.min()), np.log10(mse.mean(axis=1).values.max()), 100)\n",
    "        ax.hist(mse[data_test.signal == 0].mean(axis=1), label='qcd', histtype='step', bins=bins, density=1)\n",
    "        ax.hist(mse[data_test.signal == 1].mean(axis=1), label='signal', histtype='step', bins=bins, density=1)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        bins = np.logspace(np.log10(mse.values.min()), np.log10(mse.values.max()), 100)\n",
    "        for c in mse:\n",
    "            ax.hist(\n",
    "                mse[data_test.signal == i][c], bins=bins, \n",
    "                label=c, histtype='step'\n",
    "            )\n",
    "    ax.legend()\n",
    "    ax.set_xscale('log')\n",
    "    if i == 2:\n",
    "        ax.set_ylabel('Density', fontsize=18)\n",
    "    else:\n",
    "        ax.set_ylabel('Count', fontsize=18)\n",
    "        ax.set_xlim(1e-9, 1e0)\n",
    "    ax.grid()\n",
    "    ax.set_xlabel('VAE MSE', fontsize=18)\n",
    "    ax.set_title(name, fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65b4516",
   "metadata": {
    "id": "f65b4516"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axs = axs.flatten()\n",
    "bx, by = [np.linspace(*arg, 50) for arg in zip(z.min(axis=0), z.max(axis=0))]\n",
    "vals = []\n",
    "for i,name in enumerate(['qcd', 'signal']):\n",
    "    ax = axs[i]\n",
    "    h = ax.hist2d(z[data_test.signal == i,0], z[data_test.signal == i,1], bins=(bx, by), density=1, )\n",
    "    vals.append(h[0])\n",
    "    fig.colorbar(h[3], ax=ax, label='Test Density')\n",
    "    ax.set_xlabel('$z_0$', fontsize=18)\n",
    "    ax.set_ylabel('$z_1$', fontsize=18)\n",
    "    ax.set_title(name, fontsize=20)\n",
    "ax = axs[2]\n",
    "h = ax.pcolor(np.nan_to_num(vals[1].T/vals[0].T, 1, posinf=1), vmin=0, vmax=4)\n",
    "fig.colorbar(h, ax=ax, label='Ratio of Signal/QCD Densities',)\n",
    "ax.set_xlabel('$z_0$', fontsize=18)\n",
    "ax.set_ylabel('$z_1$', fontsize=18)\n",
    "ax.set_title('signal/qcd', fontsize=20)\n",
    "\n",
    "ax = axs[3]\n",
    "h = ax.hist2d(*ztrain.T, bins=(bx, by), norm=mpl.colors.LogNorm())\n",
    "fig.colorbar(h[3], ax=ax, label='Log Density', )\n",
    "ax.set_xlabel('$z_0$', fontsize=18)\n",
    "ax.set_ylabel('$z_1$', fontsize=18)\n",
    "ax.set_title('training set combined density', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494b0112",
   "metadata": {
    "id": "494b0112"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc,roc_auc_score\n",
    "\n",
    "name = 'Variational Autoencoder'\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "# try with other yhats! z[:,0], np.mean(z, axis=1), etc. some might work better.\n",
    "yhat = mse.mean(axis=1)\n",
    "fpr, tpr, thresh = roc_curve(data_test.signal, yhat)\n",
    "this_auc = auc(fpr, tpr)\n",
    "\n",
    "ax = axs[0]\n",
    "ax.plot(fpr, tpr, label='{}, AUC={:.4f}'.format(name, this_auc))\n",
    "ax.plot(fpr, fpr, ls=':', color='tab:grey')\n",
    "ax.set_ylabel('True Positive Rate', fontsize=18)\n",
    "ax.set_xlabel('False Positive Rate', fontsize=18)\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax = axs[1]\n",
    "ax.plot(tpr, tpr/np.sqrt(fpr))\n",
    "ax.set_xlabel('True Positive Rate', fontsize=18)\n",
    "ax.set_ylabel('Significance Improvement $\\sigma$', fontsize=18)\n",
    "ax.axhline(1.0, ls=':', color='tab:grey')\n",
    "ax.grid()\n",
    "ROCS[name] = tpr, fpr, this_auc\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4218f922",
   "metadata": {
    "id": "4218f922"
   },
   "source": [
    "We should find that the VAE does slightly better than the AE. Similar improvements to the VAE are pretty easy to make."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8364bec8",
   "metadata": {
    "id": "8364bec8"
   },
   "source": [
    "# Classification without Labels\n",
    "\n",
    "I'll guide us through the implementation of CWoLa here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65578f2",
   "metadata": {
    "id": "a65578f2"
   },
   "source": [
    "First, write code to set up a standard neural network in torch, from the skeleton code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c340cfdc",
   "metadata": {
    "id": "c340cfdc"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Network, self).__init__()\n",
    "        # define fully connected layers here\n",
    "\n",
    "    def forward(self, x):\n",
    "        # define forward here\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dfb7c0",
   "metadata": {
    "id": "33dfb7c0"
   },
   "source": [
    "Next, write code to create a dataloader for the dataset, using the `data_train` data and separating by the `sr` variable, using the feature `mjj`\n",
    "\n",
    "You should also pick a subset of the features to train with; probably it is easiest to use only a few features at first. \n",
    "`maxmass`, `minmass`, `tau21a`, and `tau21b` are a good start.\n",
    "\n",
    "Hint: Using the `between` function of pandas will be a good start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf22254c",
   "metadata": {
    "id": "cf22254c"
   },
   "outputs": [],
   "source": [
    "# create y-labels for data\n",
    "\n",
    "# define features\n",
    "\n",
    "# make a combined x and y dataset using TensorDataset, with normalization factors included\n",
    "\n",
    "# make training/validation split with random_split\n",
    "\n",
    "# make training loader using DataLoader, \n",
    "# and extract tensors for x_validation and y_validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d067cc3e",
   "metadata": {
    "id": "d067cc3e"
   },
   "source": [
    "Next, define an instance of the model and train, with the necessary parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f345505",
   "metadata": {
    "id": "8f345505"
   },
   "outputs": [],
   "source": [
    "# define model, learning rate, optimizer, etc.\n",
    "\n",
    "# track validation loss etc\n",
    "\n",
    "# make for-loop over epochs\n",
    "\n",
    "# plot loss/val loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcdeff9",
   "metadata": {
    "id": "0dcdeff9"
   },
   "source": [
    "Lastly, we need to implement an analysis of the results. This will be easy enough using the test dataset that we have set for ourselves. Make sure to use the `roc_curve` and `auc` functions from previous examples (in fact, you can almost totally copy the code!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a20322",
   "metadata": {
    "id": "39a20322"
   },
   "outputs": [],
   "source": [
    "# use cwola model to get yhat scores for the test dataset.\n",
    "# take care to use appropriate normalization factors!\n",
    "\n",
    "# use sklearn functions to calculate the true positive rate, \n",
    "# false positive rate, and AUC\n",
    "\n",
    "# plot results\n",
    "\n",
    "# add results to ROCS dictionary defined above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763caf79",
   "metadata": {
    "id": "763caf79"
   },
   "source": [
    "Lastly, we compare all of the results! This can be done fairly easily with the dictionary we have made.\n",
    "\n",
    "If you re-run all of your models, you'll see that the performances vary significantly based on trainings. For the autoencoders, this is because the training is quite random, so whether or not signal is picked up by a metric like MSE is more randomized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441de99d",
   "metadata": {
    "id": "441de99d"
   },
   "outputs": [],
   "source": [
    "# loop through ROCS dictionary and plot results, using your plotting code from above. remember the format is TPR, FPR, AUC, with key value NAME\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
